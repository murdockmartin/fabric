{"cells":[{"cell_type":"markdown","source":["### Exploring data frames\n","\n","Exploring data frames, schemas, and data types concepts\n","\n","Why use a custom schema? \n","- makes the datatype implicit and avoids data anomoly problems\n","- performance overhead required from an implied schema (results in $)\n","- incompatible column names when reading from csv files (no spaces or special characters allowed)\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"abb9bb4f-fb1c-48e7-903b-d3faf524ed97"},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","\n","dim_calendar = [(\"2024-01-01\", 1, 2, \"Mon\", 1, \"Jan\"), \n","    (\"2024-01-02\", 2, 3, \"Tue\", 1, \"Jan\"),\n","    (\"2024-01-03\", 3, 4, \"Wed\", 1, \"Jan\"),\n","    (\"2024-01-04\", 4, 5, \"Thu\", 1, \"Jan\"),\n","    (\"2024-01-05\", 5, 6, \"Fri\", 1, \"Jan\"),\n","    (\"2024-01-06\", 6, 7, \"Sat\", 1, \"Jan\"),\n","    (\"2024-01-07\", 7, 1, \"Sun\", 1, \"Jan\")\n","]\n","\n","schema = StructType([\n","    StructField(\"calendardate\",StringType() ,True),\n","    StructField(\"dayofyear\",IntegerType(),True),\n","    StructField(\"dayofweek\",IntegerType(),True),\n","    StructField(\"dayofweekname\",StringType(),True),\n","    StructField(\"monthofyear\",IntegerType(),True),\n","    StructField(\"monthname\",StringType(),True)\n","])\n","\n","df = spark.createDataFrame(data = dim_calendar, schema = schema)\n","df.printSchema()\n","df.show()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b9b63885-64f9-4c81-9458-a31780c2dcbf","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-13T20:35:07.7431719Z","session_start_time":"2024-03-13T20:35:07.995451Z","execution_start_time":"2024-03-13T20:35:17.9556322Z","execution_finish_time":"2024-03-13T20:35:21.57369Z","parent_msg_id":"b905fb44-e155-4459-b687-557a3eeef969"},"text/plain":"StatementMeta(, b9b63885-64f9-4c81-9458-a31780c2dcbf, 3, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- calendardate: string (nullable = true)\n |-- dayofyear: integer (nullable = true)\n |-- dayofweek: integer (nullable = true)\n |-- dayofweekname: string (nullable = true)\n |-- monthofyear: integer (nullable = true)\n |-- monthname: string (nullable = true)\n\n+------------+---------+---------+-------------+-----------+---------+\n|calendardate|dayofyear|dayofweek|dayofweekname|monthofyear|monthname|\n+------------+---------+---------+-------------+-----------+---------+\n|  2024-01-01|        1|        2|          Mon|          1|      Jan|\n|  2024-01-02|        2|        3|          Tue|          1|      Jan|\n|  2024-01-03|        3|        4|          Wed|          1|      Jan|\n|  2024-01-04|        4|        5|          Thu|          1|      Jan|\n|  2024-01-05|        5|        6|          Fri|          1|      Jan|\n|  2024-01-06|        6|        7|          Sat|          1|      Jan|\n|  2024-01-07|        7|        1|          Sun|          1|      Jan|\n+------------+---------+---------+-------------+-----------+---------+\n\n"]}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"19bf8cba-1437-423d-bdaa-b494a88a784c"},{"cell_type":"markdown","source":["### Spark Date Functions\n","\n","In this example, I replace the manually created columns using builtin functions for DataFrame operations. <br>\n","Information on PySpark SQL functions can be found at [spark.apache.org](https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html) \n","\n","the withColumn is can be used to: \n","- override column names when reading from csv files\n","- adding a new column to a dataframe for a calculated column "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"413a03c5-a9f0-4da2-85af-9eeb5c5fc0f6"},{"cell_type":"code","source":["from pyspark.sql.functions import col, date_format, dayofyear, dayofweek, dayofmonth, year, month, quarter, trunc, last_day\n","\n","dim_calendar = [\"2024-01-01\", \"2024-01-02\", \"2024-01-03\", \"2024-01-04\", \"2024-01-05\", \"2024-01-06\", \"2024-01-07\",\n","        \"2024-01-08\", \"2024-01-09\", \"2024-01-10\", \"2024-01-11\", \"2024-01-12\", \"2024-01-13\", \"2024-01-14\"]\n","\n","df = spark.createDataFrame(dim_calendar, \"string\").toDF(\"calendardate\")\n","df.printSchema()\n","\n","df.withColumn('dayofyear', dayofyear(col(\"calendardate\"))) \\\n","    .withColumn('dayofweek', dayofweek(col(\"calendardate\"))) \\\n","    .withColumn('dayofweekname', date_format(col(\"calendardate\"), \"EEE\")) \\\n","    .withColumn('monthofyear', month(col(\"calendardate\"))) \\\n","    .withColumn('monthname', date_format(col(\"calendardate\"), \"MMM\")) \\\n","    .withColumn('year', year(col(\"calendardate\"))) \\\n","    .withColumn(\"firstdayofmonth\", trunc(col(\"calendardate\"), \"MM\")) \\\n","    .withColumn(\"lastdayofmonth\", last_day(col(\"calendardate\"))) \\\n","    .show()\n","\n","df.printSchema()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"99b26b3d-29a4-49c7-9ab6-5a79801e600b","statement_id":35,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-13T19:02:58.5945063Z","session_start_time":null,"execution_start_time":"2024-03-13T19:02:58.9481906Z","execution_finish_time":"2024-03-13T19:02:59.7140213Z","parent_msg_id":"d5ca8975-60a2-4587-9e11-252c8959efac"},"text/plain":"StatementMeta(, 99b26b3d-29a4-49c7-9ab6-5a79801e600b, 35, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- calendardate: string (nullable = true)\n\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n|calendardate|dayofyear|dayofweek|dayofweekname|monthofyear|monthname|year|firstdayofmonth|lastdayofmonth|\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n|  2024-01-01|        1|        2|          Mon|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-02|        2|        3|          Tue|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-03|        3|        4|          Wed|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-04|        4|        5|          Thu|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-05|        5|        6|          Fri|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-06|        6|        7|          Sat|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-07|        7|        1|          Sun|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-08|        8|        2|          Mon|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-09|        9|        3|          Tue|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-10|       10|        4|          Wed|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-11|       11|        5|          Thu|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-12|       12|        6|          Fri|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-13|       13|        7|          Sat|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-14|       14|        1|          Sun|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n\nroot\n |-- calendardate: string (nullable = true)\n\n"]}],"execution_count":33,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"a84dbdf6-ba20-4434-af8c-a9761d19cdd2"},{"cell_type":"markdown","source":["### Parameters - creating a sequence of dates\n","In these cells we add parameters and using the explode and sequence functions\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5a221891-8063-474c-8782-4e840145d944"},{"cell_type":"code","source":["# Parameters can be passed from pipelines...  For our date table, we will incrementally add dates for the current month \n","# each time that we load monthly data.  \n","\n","beginDate = '2015-01-01'\n","endDate = '2024-03-31'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b9b63885-64f9-4c81-9458-a31780c2dcbf","statement_id":26,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-13T21:20:11.6189311Z","session_start_time":null,"execution_start_time":"2024-03-13T21:20:11.971518Z","execution_finish_time":"2024-03-13T21:20:12.208236Z","parent_msg_id":"b012a049-bbcd-4638-8e0e-49fe57f4bdc6"},"text/plain":"StatementMeta(, b9b63885-64f9-4c81-9458-a31780c2dcbf, 26, Finished, Available)"},"metadata":{}}],"execution_count":24,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"0a4eaaf0-a2f1-4fc4-8665-8671b59ed3b2"},{"cell_type":"code","source":["from pyspark.sql.functions import col, date_format, dayofyear, dayofweek, dayofmonth, year, weekofyear, month, quarter, trunc, last_day, explode, sequence, to_date\n","\n","df = spark.sql(f\"select explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as calendarDate\")\n","df.printSchema()\n","df.show(3)\n","\n","\n","df.withColumn('dayofyear', dayofyear(col(\"calendardate\"))) \\\n","    .withColumn('dayofweek', dayofweek(col(\"calendardate\"))) \\\n","    .withColumn('dayofweekname', date_format(col(\"calendardate\"), \"EEE\")) \\\n","    .withColumn('monthofyear', month(col(\"calendardate\"))) \\\n","    .withColumn('monthname', date_format(col(\"calendardate\"), \"MMM\")) \\\n","    .withColumn('year', year(col(\"calendardate\"))) \\\n","    .withColumn('dayofyear', dayofyear(col(\"calendardate\"))) \\\n","    .withColumn('weekofyear', weekofyear(col(\"calendardate\"))) \\\n","    .withColumn(\"firstdayofmonth\", trunc(col(\"calendardate\"), \"MM\")) \\\n","    .withColumn(\"lastdayofmonth\", last_day(col(\"calendardate\"))) \\\n","    .show()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b9b63885-64f9-4c81-9458-a31780c2dcbf","statement_id":24,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-13T20:58:12.8786422Z","session_start_time":null,"execution_start_time":"2024-03-13T20:58:13.2094304Z","execution_finish_time":"2024-03-13T20:58:13.9415181Z","parent_msg_id":"ecc9fb6a-e497-4766-acab-eb389fc3d7fe"},"text/plain":"StatementMeta(, b9b63885-64f9-4c81-9458-a31780c2dcbf, 24, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["root\n |-- calendarDate: date (nullable = false)\n\n+------------+\n|calendarDate|\n+------------+\n|  2024-01-01|\n|  2024-01-02|\n|  2024-01-03|\n+------------+\nonly showing top 3 rows\n\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n|calendarDate|dayofyear|dayofweek|dayofweekname|monthofyear|monthname|year|firstdayofmonth|lastdayofmonth|\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n|  2024-01-01|        1|        2|          Mon|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-02|        2|        3|          Tue|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-03|        3|        4|          Wed|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-04|        4|        5|          Thu|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-05|        5|        6|          Fri|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-06|        6|        7|          Sat|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-07|        7|        1|          Sun|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-08|        8|        2|          Mon|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-09|        9|        3|          Tue|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-10|       10|        4|          Wed|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-11|       11|        5|          Thu|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-12|       12|        6|          Fri|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-13|       13|        7|          Sat|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n|  2024-01-14|       14|        1|          Sun|          1|      Jan|2024|     2024-01-01|    2024-01-31|\n+------------+---------+---------+-------------+-----------+---------+----+---------------+--------------+\n\n"]}],"execution_count":22,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"880c93c9-b481-45d5-8cfe-a434b5473025"},{"cell_type":"markdown","source":["### Writing to a Delta table\n","In this cell,  we write the data to a Delta table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6ca6ead5-97bb-4f04-9945-182f36f15624"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2a4e5a76-a563-445d-ba5a-ef8942ecb2cf"},{"cell_type":"code","source":["from pyspark.sql.functions import col, date_format, dayofweek, year, dayofyear, weekofyear, month, quarter, trunc, last_day, explode, sequence, to_date\n","\n","deltaTableName = \"dim_calendar\"\n","\n","df = spark.sql(f\"select explode(sequence(to_date('{beginDate}'), to_date('{endDate}'), interval 1 day)) as calendarDate\")\n","\n","df.withColumn('dayofyear', dayofyear(col(\"calendardate\"))) \\\n","    .withColumn('dayofweek', dayofweek(col(\"calendardate\"))) \\\n","    .withColumn('dayofweekname', date_format(col(\"calendardate\"), \"EEE\")) \\\n","    .withColumn('monthofyear', month(col(\"calendardate\"))) \\\n","    .withColumn('monthname', date_format(col(\"calendardate\"), \"MMM\")) \\\n","    .withColumn('year', year(col(\"calendardate\"))) \\\n","    .withColumn('dayofyear', dayofyear(col(\"calendardate\"))) \\\n","    .withColumn('weekofyear', weekofyear(col(\"calendardate\"))) \\\n","    .withColumn('quarter', quarter(col(\"calendardate\"))) \\\n","    .withColumn(\"firstdayofmonth\", trunc(col(\"calendardate\"), \"MM\")) \\\n","    .withColumn(\"lastdayofmonth\", last_day(col(\"calendardate\"))) \\\n","    .withColumn('monthandyear', date_format(col(\"calendardate\"), \"yyyy-MM\")) \\\n","    .write.mode(\"overwrite\").format(\"delta\").saveAsTable(deltaTableName)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"b9b63885-64f9-4c81-9458-a31780c2dcbf","statement_id":27,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-13T21:20:26.3386581Z","session_start_time":null,"execution_start_time":"2024-03-13T21:20:26.6745602Z","execution_finish_time":"2024-03-13T21:20:32.9291836Z","parent_msg_id":"d1d83b18-95c3-4e38-9f00-9ccf042fd811"},"text/plain":"StatementMeta(, b9b63885-64f9-4c81-9458-a31780c2dcbf, 27, Finished, Available)"},"metadata":{}}],"execution_count":25,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"6f021cb3-6b91-471b-ab30-b0899edcec4b"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"known_lakehouses":[{"id":"a2db409c-43eb-4218-a351-cf2bc3c98d50"},{"id":"241a8454-878c-4fa0-82c5-3996a743b2ef"}],"default_lakehouse":"a2db409c-43eb-4218-a351-cf2bc3c98d50","default_lakehouse_name":"ub_enriched_engineering","default_lakehouse_workspace_id":"45516964-41e4-478d-bf96-0628e0339cc3"}}},"nbformat":4,"nbformat_minor":5}