{"cells":[{"cell_type":"markdown","source":["### Loading data to Lakehouse\n","\n","There is no single best way to load data into the a lakehouse.  This workbook will use these techniques: \n","\n","- Simple drag and drop csv or Excel files using \"OneLake File Explorer\" or the Upload feature\n","- From a notebook use Python to read a csv file:  Raw data will be stored in  \n","\n","\n","We are not dealing with large amounts of data, and when we update our enriched data, we will replace the full dataset each time. We are using public data sources, so we need to be prepared if they change the source format.  The public data sources used in this workbook are\n","- U.S. Post Office\n","- U.S. Census 2020 (States, Counties, CBSA, ZCTAS, Places, Blocks, Address Counts)\n","- "],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a69b95a8-5619-4c7f-a728-f1c275a83300"},{"cell_type":"code","source":["# Parameters used \n","# RawLakehouse and CuratedLakehouse\n","# directory used for storing files\n","\n","rawlakehousefiles = \"abfss://45516964-41e4-478d-bf96-0628e0339cc3@onelake.dfs.fabric.microsoft.com/241a8454-878c-4fa0-82c5-3996a743b2ef/Files\"\n","enrichedlakehousefiles = \"abfss://45516964-41e4-478d-bf96-0628e0339cc3@onelake.dfs.fabric.microsoft.com/a2db409c-43eb-4218-a351-cf2bc3c98d50/Files\"\n","directory = \"/Geography/\"\n","rawlakehouse = \"ub_raw_engineering\"\n","enrichedlakehouse = \"ub_enriched_engineering\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":12,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:45:59.3794039Z","session_start_time":null,"execution_start_time":"2024-03-28T14:45:59.7904667Z","execution_finish_time":"2024-03-28T14:46:00.0156545Z","parent_msg_id":"e7f1a5da-494a-445a-bed0-1c39cb1dd75e"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 12, Finished, Available)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"tags":["parameters"]},"id":"53790375-a391-40c5-8df2-f9d63e420410"},{"cell_type":"markdown","source":["### U.S. Postal Service\n","\n","Postal Codes:  US Postal Service  (https://postalpro.usps.com/ZIP_Locale_Detail)\n","<br>A File is downloaded in Excel xlsx format and saved to the Geography directory using OneLake File Explorer \n","<br>\n","<br>Pandas is used to read the raw excel file, update the headers, specify data types  (pdzips)\n","<br>A Spark DataFrame is used to write the data in delta format (zips)\n","<br>\n","<br>Note: Excel \n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"c9f9c4e7-0378-4562-95b9-4c4ed44d42e6"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","filename = \"ZIP_Locale_Detail.xlsx\"\n","sheetname = \"ZIP_DETAIL\"\n","deltaTableName = enrichedlakehouse+\".geo_zips\"\n","\n","# Returns a Pandas DataFrame reading data from Excel\n","pdzips = pd.read_excel(rawlakehousefiles + directory + filename, sheet_name=sheetname, \\\n","header=0,names=['AreaName', 'AreaCode', 'DistrictName', 'DistrictNo', 'DeliveryZipCode', 'LocaleName', 'PhysicalDelvAddr', 'PhysicalCity', \\\n","'PhysicalState', 'PhysicalZip', 'PhysicalZip4'], skiprows=1, dtype={'DistrictNo': int, 'DeliveryZipCode': int, 'PhysicalZip': int, 'PhysicalZip4': str})\n","\n","# Returns a Spark DataFrame from the Pandas DataFrame\n","zips = spark.createDataFrame(pdzips)\n","\n","# Only needed when writing the initial code... commented out for production\n","# zips.show()\n","# zips.printSchema()\n","\n","# Write the data in delta format to the enrichedlakehouse\n","zips.write.format(\"delta\").mode(\"overwrite\")\\\n",".saveAsTable(deltaTableName)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":15,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:47:24.9032947Z","session_start_time":null,"execution_start_time":"2024-03-28T14:47:25.3442338Z","execution_finish_time":"2024-03-28T14:47:52.8021699Z","parent_msg_id":"61e6c547-474e-4c8b-87a8-c32330acfd64"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 15, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages/openpyxl/worksheet/header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"]}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"4f5cae8f-ffec-46ec-900f-b36ccb444c2a"},{"cell_type":"markdown","source":["#### U.S. Census Bureau"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d29dd517-a9b6-403c-b8e9-05ded27bd65d"},{"cell_type":"markdown","source":["##### State Codes\n","Source Data:  US Census TIGER Data Products (https://www.census.gov/programs-surveys/geography/guidance/tiger-data-products-guide.html)\n","<br>File is downloaded in csv format and saved to the Geography directory using OneLake File Explorer \n","<br>A Spark DataFrame is used to read the csv file using a custom schema, then write the data in delta format (statedf)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"700644c7-15ef-4017-b8fb-36b714bb6730"},{"cell_type":"code","source":["from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n","\n","filename = rawlakehousefiles+directory+\"TigerState.csv\"\n","deltaTableName = enrichedlakehouse+\".geo_state\"\n","\n","stateschema = StructType([\n","    StructField(\"region\",IntegerType() ,True),\n","    StructField(\"division\",IntegerType(),True),\n","    StructField(\"statefp\",IntegerType(),True),\n","    StructField(\"statens\",IntegerType(),True),\n","    StructField(\"geoid\",IntegerType(),True),\n","    StructField(\"geofq\",IntegerType(),True),\n","    StructField(\"stusps\",StringType(),True),\n","    StructField(\"name\",StringType(),True),\n","    StructField(\"lsad\",StringType(),True),\n","    StructField(\"mtfcc\",StringType(),True),\n","    StructField(\"funcstat\",StringType(),True),\n","    StructField(\"aland\",IntegerType(),True),\n","    StructField(\"awater\",IntegerType(),True),\n","    StructField(\"intptlat\",FloatType(),True),\n","    StructField(\"intptlon\",FloatType(),True)    \n","])\n","\n","# Returns a Spark DataFrame reading data from csv \n","statedf = spark.read.csv(filename, schema=stateschema, header=True) \\\n",".write.format(\"delta\").mode(\"overwrite\") \\\n",".saveAsTable(deltaTableName) \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":16,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:49:35.0135931Z","session_start_time":null,"execution_start_time":"2024-03-28T14:49:35.5749264Z","execution_finish_time":"2024-03-28T14:49:40.4585499Z","parent_msg_id":"53075555-936e-4b89-a582-c82b5e202617"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 16, Finished, Available)"},"metadata":{}}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"36521ba9-12ff-4401-89a3-1dcaab97223b\",\"activityId\":\"deda66e5-7007-484a-b661-ad4b23a8fa99\",\"applicationId\":\"application_1711635498394_0001\",\"jobGroupId\":\"16\",\"advices\":{\"info\":1}}"},"collapsed":false},"id":"aebab9e6-64dc-4af8-a0de-ec83760020da"},{"cell_type":"code","source":["# Creates County Geography Table\n","# Source data:  Topologically Integrated Geographic Encoding and Referencing system \n","#    State Codes:  US Census TIGER Data Products (https://www.census.gov/programs-surveys/geography/guidance/tiger-data-products-guide.html)\n","#    File is downloaded in csv format and saved to the Geography directory using OneLake File Explorer \n","#\n","# A Spark DataFrame is used to read the csv file using a custom schema, then write the data in delta format (statedf)\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n","\n","filename = rawlakehousefiles+directory+\"TigerCounty.csv\"\n","deltaTableName = enrichedlakehouse+\".geo_county\"\n","\n","countyschema = StructType([\n","    StructField(\"statefp\",IntegerType(),True),\n","    StructField(\"countyfp\",IntegerType(),True),\n","    StructField(\"countyns\",IntegerType(),True),\n","    StructField(\"geoid\",IntegerType(),True),\n","    StructField(\"geofq\",IntegerType(),True),\n","    StructField(\"name\",StringType(),True),\n","    StructField(\"namelsad\",StringType(),True),\n","    StructField(\"lsad\",StringType(),True),\n","    StructField(\"classfp\",StringType(),True),\n","    StructField(\"mtfcc\",StringType(),True),\n","    StructField(\"csafp\",IntegerType(),True),\n","    StructField(\"cbsafp\",IntegerType(),True),\n","    StructField(\"metdivfp\",IntegerType(),True),  \n","    StructField(\"funcstat\",StringType(),True),\n","    StructField(\"aland\",IntegerType(),True),\n","    StructField(\"awater\",IntegerType(),True),\n","    StructField(\"intptlat\",FloatType(),True),\n","    StructField(\"intptlon\",FloatType(),True)    \n","])\n","\n","\n","# Returns a Spark DataFrame reading data from csv \n","countydf = spark.read.csv(filename, schema=countyschema, header=True) \\\n",".write.format(\"delta\").mode(\"overwrite\") \\\n",".saveAsTable(deltaTableName) \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":17,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:51:44.2473008Z","session_start_time":null,"execution_start_time":"2024-03-28T14:51:44.6295705Z","execution_finish_time":"2024-03-28T14:51:49.409623Z","parent_msg_id":"463ac186-7536-4353-90d1-15dcf4005d37"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 17, Finished, Available)"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"36521ba9-12ff-4401-89a3-1dcaab97223b\",\"activityId\":\"deda66e5-7007-484a-b661-ad4b23a8fa99\",\"applicationId\":\"application_1711635498394_0001\",\"jobGroupId\":\"17\",\"advices\":{\"info\":1}}"},"collapsed":false,"microsoft":{}},"id":"d066a327-df80-430e-a3a3-610c1e510087"},{"cell_type":"code","source":["# Creates CBSA Table (Core Based Statistical Area)\n","# Source data:  Topologically Integrated Geographic Encoding and Referencing system \n","#    State Codes:  US Census TIGER Data Products (https://www.census.gov/programs-surveys/geography/guidance/tiger-data-products-guide.html)\n","#    File is downloaded in csv format and saved to the Geography directory using OneLake File Explorer \n","#\n","# A Spark DataFrame is used to read the csv file using a custom schema, then write the data in delta format (statedf)\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n","\n","filename = rawlakehousefiles+directory+\"TigerCbsa.csv\"\n","deltaTableName = enrichedlakehouse+\".geo_cbsa\"\n","\n","cbsaschema = StructType([\n","    StructField(\"csafp\",IntegerType(),True),\n","    StructField(\"cbsafp\",IntegerType(),True),\n","    StructField(\"geoid\",IntegerType(),True),\n","    StructField(\"geofq\",IntegerType(),True),\n","    StructField(\"name\",StringType(),True),\n","    StructField(\"namelsad\",StringType(),True),\n","    StructField(\"memi\",StringType(),True),\n","    StructField(\"mtfcc\",StringType(),True),\n","    StructField(\"aland\",IntegerType(),True),\n","    StructField(\"awater\",IntegerType(),True),\n","    StructField(\"intptlat\",FloatType(),True),\n","    StructField(\"intptlon\",FloatType(),True)    \n","])\n","\n","\n","# Returns a Spark DataFrame reading data from csv \n","countydf = spark.read.csv(filename, schema=cbsaschema, header=True) \\\n",".write.format(\"delta\").mode(\"overwrite\") \\\n",".saveAsTable(deltaTableName) \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":18,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:53:10.6755126Z","session_start_time":null,"execution_start_time":"2024-03-28T14:53:11.1506141Z","execution_finish_time":"2024-03-28T14:53:15.9712326Z","parent_msg_id":"8f5d61ed-2911-4694-870c-bbbe7072b274"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 18, Finished, Available)"},"metadata":{}}],"execution_count":16,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"36521ba9-12ff-4401-89a3-1dcaab97223b\",\"activityId\":\"deda66e5-7007-484a-b661-ad4b23a8fa99\",\"applicationId\":\"application_1711635498394_0001\",\"jobGroupId\":\"18\",\"advices\":{\"info\":1}}"},"microsoft":{},"collapsed":false},"id":"032a2fd3-44b6-43a5-bb30-47a98367cc31"},{"cell_type":"code","source":["# Creates ZCTA Table (Zip Code Tabulation Area)\n","# Source data:  Topologically Integrated Geographic Encoding and Referencing system \n","#    State Codes:  US Census TIGER Data Products (https://www.census.gov/programs-surveys/geography/guidance/tiger-data-products-guide.html)\n","#    File is downloaded in csv format and saved to the Geography directory using OneLake File Explorer \n","#\n","# A Spark DataFrame is used to read the csv file using a custom schema, then write the data in delta format (statedf)\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n","\n","filename = rawlakehousefiles+directory+\"TigerZCTA.csv\"\n","deltaTableName = enrichedlakehouse+\".geo_zcta\"\n","\n","zctaschema = StructType([\n","    StructField(\"zcta\",IntegerType(),True),\n","    StructField(\"geoid\",IntegerType(),True),\n","    StructField(\"geofq\",IntegerType(),True),\n","    StructField(\"classfp\",StringType(),True),\n","    StructField(\"mtfcc\",StringType(),True),\n","    StructField(\"funcstat\",StringType(),True),\n","    StructField(\"aland\",IntegerType(),True),\n","    StructField(\"awater\",IntegerType(),True),\n","    StructField(\"intptlat\",FloatType(),True),\n","    StructField(\"intptlon\",FloatType(),True)    \n","])\n","\n","\n","# Returns a Spark DataFrame reading data from csv \n","zctadf = spark.read.csv(filename, schema=zctaschema, header=True) \\\n",".write.format(\"delta\").mode(\"overwrite\") \\\n",".saveAsTable(deltaTableName) \n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"deda66e5-7007-484a-b661-ad4b23a8fa99","statement_id":19,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-28T14:54:12.6925382Z","session_start_time":null,"execution_start_time":"2024-03-28T14:54:13.1011745Z","execution_finish_time":"2024-03-28T14:54:17.8968947Z","parent_msg_id":"bdc99439-bf62-44fb-8722-02ec8c6b98e3"},"text/plain":"StatementMeta(, deda66e5-7007-484a-b661-ad4b23a8fa99, 19, Finished, Available)"},"metadata":{}}],"execution_count":17,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"advisor":{"adviceMetadata":"{\"artifactId\":\"36521ba9-12ff-4401-89a3-1dcaab97223b\",\"activityId\":\"deda66e5-7007-484a-b661-ad4b23a8fa99\",\"applicationId\":\"application_1711635498394_0001\",\"jobGroupId\":\"19\",\"advices\":{\"info\":1}}"}},"id":"127238e3-7487-404b-bc41-ebcea9038551"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"241a8454-878c-4fa0-82c5-3996a743b2ef","default_lakehouse_name":"ub_raw_engineering","default_lakehouse_workspace_id":"45516964-41e4-478d-bf96-0628e0339cc3","known_lakehouses":[{"id":"241a8454-878c-4fa0-82c5-3996a743b2ef"},{"id":"a2db409c-43eb-4218-a351-cf2bc3c98d50"}]}}},"nbformat":4,"nbformat_minor":5}